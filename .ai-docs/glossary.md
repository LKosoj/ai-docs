# Глоссарий

| Термин | Описание |
|-------|--------|
| **`ai_docs`** | CLI-инструмент для автоматической генерации технической документации на основе исходного кода и конфигурационных файлов с использованием LLM. Поддерживает анализ локальных и удалённых Git-репозиториев, генерацию `README.md` и статического сайта через MkDocs. |
| **`README.md`** | Краткий обзор проекта, генерируемый инструментом. Содержит описание назначения, структуры, ключевых технологий и способа запуска. Перезаписывается только с флагом `--force`. |
| **`.ai-docs/`** | Директория, содержащая сгенерированные Markdown-файлы документации. Создаётся в выходной директории и используется как `docs_dir` для MkDocs. |
| **`mkdocs.yml`** | Конфигурационный файл сайта документации. Генерируется автоматически, включает настройки навигации, плагинов (`search`, `mermaid2`), расширений Markdown и параметров для локального хостинга при использовании `--local-site`. |
| **`ai_docs_site/`** | Выходная директория со статическим сайтом документации, собранная с помощью MkDocs. Создаётся при запуске с флагом `--mkdocs`. |
| **`.ai_docs_cache/`** | Директория кэширования, хранящая `index.json` (метаданные файлов) и `llm_cache.json` (кешированные ответы LLM). Ускоряет повторную генерацию за счёт пропуска неизменных файлов. |
| **`.ai-docs/changes.md`** | Отчёт в формате Markdown, фиксирующий изменения с момента последнего запуска: добавленные, изменённые, удалённые файлы, перегенерированные разделы и краткое резюме. |
| **`LLMClient`** | Класс для взаимодействия с API языковых моделей (например, GPT). Поддерживает кэширование по хешу запроса, настройку модели, температуры, лимитов токенов и работу через прокси-провайдеры (через `OPENAI_BASE_URL`). |
| **`scan_source()`** | Основная функция сканирования исходников. Обрабатывает локальные пути и Git-репозитории, применяет фильтрацию по `.gitignore`, `include`/`exclude`, пропускает бинарные и слишком большие файлы. Возвращает объект `ScanResult`. |
| **`ScanResult`** | Результат сканирования: содержит корневой путь, список обрабатываемых файлов, исходный источник и имя репозитория. Используется как вход для генерации документации. |
| **`classify_type()`** | Функция определения типа файла (например, `code`, `config`, `infra`) на основе расширения и имени. Используется для группировки в документации. |
| **`detect_domains()`** | Определяет технологии, связанные с файлом (например, `kubernetes`, `terraform`, `docker`), на основе пути, имени и фрагмента содержимого. |
| **`is_infra()`** | Проверяет, относится ли файл к инфраструктурным компонентам (на основе доменов). Используется для выделения разделов "Инфраструктура" и "Конфиги". |
| **`chunk_text()`** | Разбивает текст на чанки по заданному лимиту токенов с использованием `tiktoken`. Применяется при суммаризации больших файлов для соблюдения ограничений контекста LLM. |
| **`summarize_file()`** | Генерирует краткое описание содержимого файла с помощью LLM. Разбивает на чанки, отправляет промпты с контекстом (тип, домены), объединяет ответы. Результат сохраняется в `.ai-docs/`. |
| **`build_mkdocs_yaml()`** | Формирует содержимое `mkdocs.yml` как строку YAML. Настраивает навигацию, плагины, пути и параметры для локального хостинга при необходимости. |
| **`write_docs_files()`** | Записывает Markdown-файлы в указанную директорию, создавая промежуточные подкаталоги. Используется для размещения сгенерированной документации. |
| **`CacheManager`** | Управляет кэшем: загружает/сохраняет `index.json` и `llm_cache.json`, выполняет сравнение файлов (`diff_files`) для определения изменений (added, modified, deleted). |
| **`format_changes_md()`** | Формирует отчёт об изменениях в Markdown. Группирует результаты `diff_files` и список перегенерированных разделов в читаемый формат. |
| **`--local-site`** | Флаг CLI, настраивающий `mkdocs.yml` для локального запуска: `site_url: ""`, `use_directory_urls: false`. Полезен при публикации через `file://` или статический хостинг без роутинга. |
| **`--no-cache`** | Отключает использование кэша LLM и индекса файлов. Принудительно перегенерирует все разделы, даже если файлы не изменились. |
| **`--force`** | Разрешает перезапись существующего `README.md` без предупреждения. |
| **`AI_DOCS_THREADS`** | Переменная окружения, задающая количество потоков по умолчанию для параллельной обработки файлов. |
| **`OPENAI_API_KEY`** | Обязательная переменная окружения с ключом доступа к API LLM. |
| **`OPENAI_MODEL`** | Модель LLM, используемая по умолчанию (например, `gpt-4o-mini`). Может быть переопределена в `.env` или CLI. |
| **`OPENAI_TEMPERATURE`** | Параметр генерации, контролирующий "креативность" ответов. Для документации рекомендуется низкое значение (по умолчанию `0.2`). |
