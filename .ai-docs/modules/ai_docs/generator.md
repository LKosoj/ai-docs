# ai_docs/generator

Модуль отвечает за генерацию технической документации на основе исходных файлов проекта с использованием LLM.  
Он анализирует содержимое файлов, строит краткие описания (суммаризации), формирует структурированную документацию в формате Markdown,  
а также поддерживает интеграцию с MkDocs и кэширование промежуточных результатов для повышения производительности.  
Поддерживается многопоточная обработка и фильтрация тестовых файлов.

Ключевые структуры данных  
files — Список словарей с метаданными файлов: путь, содержимое, тип, домены и размер  
file_map — Словарь, сопоставляющий путь к файлу с его хешем, размером, типом, доменами и содержимым  
llm_cache — Кэш для хранения результатов запросов к LLM, чтобы избежать повторных вычислений

generate_docs(files: List[Dict], output_root: Path, cache_dir: Path, llm: LLMClient, language: str, write_readme: bool, write_mkdocs: bool, use_cache: bool = True, threads: int = 1, local_site: bool = False, force: bool = False) -> None  
Генерирует документацию по проекту: суммаризует файлы, создаёт разделы и опционально README и mkdocs.yml.  
Аргументы  
files — Список файлов с их содержимым и метаданными  
output_root — Корневая директория для вывода сгенерированной документации  
cache_dir — Директория для хранения кэша (промежуточных и итоговых данных)  
llm — Клиент для взаимодействия с языковой моделью  
language — Язык документации (например, "ru" или "en")  
write_readme — Флаг, указывающий, нужно ли генерировать README.md  
write_mkdocs — Флаг, указывающий, нужно ли генерировать mkdocs.yml  
use_cache — Флаг использования кэша для LLM-запросов и метаданных файлов  
threads — Количество потоков для параллельной обработки файлов  
local_site — Флаг, активирующий локальный режим (влияет на ссылки в документации)  
force — Принудительная перегенерация без учёта кэша (не реализовано напрямую, но может влиять через cache)  
Возвращает  
Ничего не возвращает  
Исключения  
Может выбрасывать исключения при ошибках чтения/записи файлов, сбоях LLM или парсинге конфигураций

---
_is_test_path(path: str) -> bool  
Определяет, является ли путь тестовым (по имени папки или файла).  
Аргументы  
path — Путь к файлу или директории  
Возвращает  
True, если путь соответствует шаблону тестового файла или директории

---
_collect_dependencies(files: Dict[str, Dict]) -> List[str]  
Собирает список зависимостей из pyproject.toml, requirements.txt и package.json.  
Аргументы  
files — Словарь файлов с их содержимым  
Возвращает  
Отсортированный список уникальных строк с названиями и версиями зависимостей

---
_generate_section(llm: LLMClient, llm_cache: Dict[str, str], title: str, context: str, language: str) -> str  
Генерирует один раздел документации с помощью LLM, включая Mermaid-диаграмму для архитектуры.  
Аргументы  
llm — Клиент языковой модели  
llm_cache — Кэш для LLM-ответов  
title — Заголовок раздела (например, "Архитектура")  
context — Контекст (суммаризации файлов), на основе которого генерируется раздел  
language — Язык вывода  
Возвращает  
Сгенерированный Markdown-контент раздела без дублирующего заголовка

---
_strip_duplicate_heading(content: str, title: str) -> str  
Удаляет первый заголовок из текста, если он дублирует указанный заголовок раздела.  
Аргументы  
content — Текст Markdown, возможно, с заголовком  
title — Ожидаемый заголовок раздела  
Возвращает  
Текст без дублирующего заголовка

---
_generate_readme(llm: LLMClient, llm_cache: Dict[str, str], project_name: str, overview_context: str, language: str) -> str  
Генерирует краткий README.md на основе общего контекста проекта.  
Аргументы  
llm — Клиент языковой модели  
llm_cache — Кэш LLM-ответов  
project_name — Название проекта  
overview_context — Обобщённый контекст проекта (например, суммаризация ключевых файлов)  
language — Язык документации  
Возвращает  
Сгенерированный Markdown-текст README

---
_truncate_context(context: str, model: str, max_tokens: int) -> str  
Обрезает контекст до указанного количества токенов, если он слишком длинный.  
Аргументы  
context — Входной текст  
model — Название модели для подсчёта токенов  
max_tokens — Максимальное количество токенов  
Возвращает  
Обрезанный текст (первый чанк, если исходный слишком длинный)

---
summarize_file(content: str, file_type: str, domains: List[str], llm: LLM, llm_cache: Cache, model: str, is_module: bool = False) -> str  
Генерирует краткое резюме содержимого файла с использованием LLM  
Аргументы  
content — исходное содержимое файла для анализа  
file_type — тип файла (например, "code", "config")  
domains — список доменов, к которым относится файл  
llm — экземпляр языковой модели для генерации текста  
llm_cache — кэш для хранения и повторного использования результатов LLM  
model — имя модели, используемой в LLM  
is_module — флаг, указывающий, что файл является модулем (требует детализированного резюме)  
Возвращает  
Сгенерированное текстовое резюме файла

---
write_summary(output_dir: Path, file_path: str, summary: str) -> Path  
Записывает резюме файла в указанный каталог, сохраняя структуру путей  
Аргументы  
output_dir — корневой каталог для сохранения резюме  
file_path — исходный путь к файлу, по которому определяется относительный путь  
summary — текст резюме для записи  
Возвращает  
Путь к созданному файлу резюме

---
read_text_file(path: Path) -> str  
Считывает содержимое текстового файла в строку  
Аргументы  
path — путь к файлу  
Возвращает  
Содержимое файла как строка

---
_submit_section(out_path: str, title: str, context: str)  
Добавляет задачу генерации секции в пул потоков или выполняет немедленно  
Аргументы  
out_path — путь к файлу, куда будет сохранён результат  
title — заголовок секции  
context — входной контекст для генерации содержимого через LLM

---
format_changes_md(added: Dict, modified: Dict, deleted: Dict, regenerated: List[str], summary: str) -> str  
Форматирует сводку изменений в виде Markdown  
Аргументы  
added — словарь добавленных файлов  
modified — словарь изменённых файлов  
deleted — словарь удалённых файлов  
regenerated — список перегенерированных секций  
summary — сгенерированное резюме изменений  
Возвращает  
Markdown-строка с деталями изменений

---
write_docs_files(docs_dir: Path, docs_files: Dict[str, str]) -> None  
Записывает все сгенерированные файлы документации на диск  
Аргументы  
docs_dir — корневая директория документации  
docs_files — словарь с путями и содержимым файлов

---
build_mkdocs_yaml(site_name: str, sections: Dict[str, str], configs: Dict[str, str], has_modules: bool, module_nav_paths: Optional[List[str]], local_site: bool) -> str  
Генерирует содержимое файла mkdocs.yml  
Аргументы  
site_name — имя сайта документации  
sections — заголовки основных секций  
configs — отображение доменов в пути файлов конфигураций  
has_modules — флаг наличия модульной документации  
module_nav_paths — пути к страницам модулей для навигации  
local_site — если True, настраивает вывод в docs/_site  
Возвращает  
Строка в формате YAML для mkdocs.yml

---
class cache  
Управляет сохранением и загрузкой индекса и кэша LLM  
Методы  
save_index(index: Dict) — сохраняет индекс файлов и состояния секций  
save_llm_cache(llm_cache) — сохраняет кэш запросов к языковой модели
