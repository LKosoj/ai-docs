# ai_docs/generator

Модуль отвечает за генерацию технической документации проекта на основе анализа исходных файлов с использованием LLM. Собирает контекст, разбивает его на разделы, генерирует Markdown-документы, включая архитектуру, зависимости и модули. Поддерживает кэширование, многопоточную обработку и интеграцию с MkDocs. Результат — структурированная документация в формате, пригодном для публикации.

Ключевые структуры данных  
SECTION_TITLES — Словарь соответствия внутренних ключей разделов и их локализованных заголовков  
DOMAIN_TITLES — Словарь отображения доменов (например, kubernetes) в читаемые названия

---
def _is_test_path(path: str) -> bool  
Проверяет, является ли путь тестовым (по имени папки или файла)  
Аргументы  
path — Путь к файлу или директории  
Возвращает  
True, если путь соответствует шаблону тестового файла или директории

---
def _collect_dependencies(files: Dict[str, Dict]) -> List[str]  
Собирает список зависимостей из pyproject.toml, requirements.txt и package.json  
Аргументы  
files — Словарь файлов с метаданными, включая содержимое  
Возвращает  
Отсортированный список уникальных строк зависимостей в формате "имя версия"

---
def _generate_section(llm: LLMClient, llm_cache: Dict[str, str], title: str, context: str, language: str) -> str  
Генерирует содержимое одного раздела документации с помощью LLM  
Аргументы  
llm — Клиент для взаимодействия с языковой моделью  
llm_cache — Кэш для ответов LLM  
title — Заголовок раздела  
context — Контекст для генерации  
language — Язык вывода  
Возвращает  
Сгенерированный Markdown-контент раздела без дублирующего заголовка

---
def _strip_duplicate_heading(content: str, title: str) -> str  
Удаляет первый заголовок из текста, если он дублирует указанный заголовок раздела  
Аргументы  
content — Входной текст  
title — Ожидаемый заголовок  
Возвращает  
Текст без дублирующего заголовка

---
def _generate_readme(llm: LLMClient, llm_cache: Dict[str, str], project_name: str, overview_context: str, language: str) -> str  
Генерирует краткий README.md на основе общего контекста проекта  
Аргументы  
llm — Клиент LLM  
llm_cache — Кэш LLM  
project_name — Название проекта  
overview_context — Общий контекст проекта  
language — Язык документации  
Возвращает  
Сгенерированный Markdown-текст README

---
def _truncate_context(context: str, model: str, max_tokens: int) -> str  
Обрезает контекст до указанного лимита токенов, если он превышает лимит  
Аргументы  
context — Исходный текст  
model — Название модели для подсчёта токенов  
max_tokens — Максимальное количество токенов  
Возвращает  
Обрезанный или исходный текст, укладывающийся в лимит

---
def _first_paragraph(text: str) -> str  
Извлекает первый абзац текста, пропуская заголовки и пустые строки  
Аргументы  
text — Входной текст  
Возвращает  
Первый абзац как одна строка

---
def _build_docs_index(output_root: Path, docs_dir: Path, docs_files: Dict[str, str], file_map: Dict[str, Dict], module_pages: Dict[str, str]) -> Dict[str, object]  
Формирует JSON-индекс документации с метаданными и структурой  
Аргументы  
output_root — Корневая директория вывода  
docs_dir — Директория с документацией  
docs_files — Сгенерированные файлы документации  
file_map — Карта исходных файлов с метаданными  
module_pages — Сопоставление модулей и путей к страницам  
Возвращает  
Словарь с метаинформацией о сгенерированной документации

---
def generate_docs(files: List[Dict], output_root: Path, cache_dir: Path, llm: LLMClient, language: str, write_readme: bool, write_mkdocs: bool, use_cache: bool = True, threads: int = 1)  
Основная функция генерации документации по списку файлов  
Аргументы  
files — Список файлов с метаданными (путь, содержимое и др.)  
output_root — Корневая директория для вывода документации  
cache_dir — Директория для кэширования  
llm — Клиент языковой модели  
language — Язык документации (например, "ru")  
write_readme — Флаг: генерировать ли README.md  
write_mkdocs — Флаг: генерировать ли mkdocs.yml  
use_cache — Использовать кэш LLM (по умолчанию True)  
threads — Количество потоков для параллельной обработки (по умолчанию 1)  
Исключения  
Может выбрасывать исключения при ошибках чтения/записи файлов или сбоях LLM

---
def process_files(files: List[Dict], cache_dir: Path, llm: LLM, use_cache: bool = True, threads: int = 4, local_site: bool = False, force: bool = False) -> None  
Обрабатывает список файлов: суммаризует содержимое, обновляет кэш и восстанавливает недостающие промежуточные данные  
Аргументы  
files — список файлов с полями path, content, size, type, domains  
cache_dir — директория для хранения кэша и промежуточных данных  
llm — экземпляр модели языковой модели для генерации суммаризаций  
use_cache — флаг использования кэширования LLM-запросов  
threads — количество потоков для параллельной обработки  
local_site — флаг, указывающий на генерацию для локального сайта (не влияет напрямую в текущей реализации)  
force — флаг принудительной перегенерации (не используется в текущей реализации)  
Возвращает  
None  
Исключения  
Может выбрасывать исключения при ошибках чтения/записи файлов или сбоях в LLM, которые логируются и добавляются в список errors

---
def _write_summary(content: str, output_dir: Path, relative_path: str) -> Path  
Записывает суммаризированный контент в файл в указанной директории, сохраняя структуру путей  
Аргументы  
content — текст суммаризации для записи  
output_dir — корневая директория для сохранения  
relative_path — относительный путь файла, определяющий поддиректорию и имя файла  
Возвращает  
Путь к созданному файлу суммаризации  
Исключения  
IOError — при ошибках записи файла

---
def summarize_file(content: str, file_type: str, domains: List[str], llm: LLM, llm_cache: Optional[Dict] = None, model: Optional[str] = None, is_module: bool = False) -> str  
Генерирует текстовую суммаризацию содержимого файла с использованием LLM, с разными шаблонами для обычных и модульных суммаризаций  
Аргументы  
content — исходное содержимое файла  
file_type — тип файла (например, "code", "text")  
domains — список доменов, связанных с файлом  
llm — экземпляр языковой модели  
llm_cache — опциональный кэш для хранения и повторного использования ответов LLM  
model — имя модели LLM (передаётся в кэш)  
is_module — флаг, указывающий, что требуется детальная (модульная) суммаризация  
Возвращает  
Сгенерированный текст суммаризации  
Исключения  
Exception — при ошибках взаимодействия с LLM или кэшем

---
def write_summary(output_dir: Path, source_path: str, summary: str) -> Path  
Сохраняет сгенерированную аннотацию в файловой системе  
Аргументы  
output_dir — директория, куда сохраняется аннотация  
source_path — исходный путь к файлу, на основе которого генерируется имя  
summary — текст аннотации для сохранения  
Возвращает  
Путь к созданному файлу аннотации

---
def read_text_file(path: Path) -> str  
Считывает содержимое текстового файла  
Аргументы  
path — путь к файлу  
Возвращает  
Содержимое файла в виде строки

---
def _truncate_context(text: str, model: str, max_tokens: int) -> str  
Обрезает текст до указанного лимита токенов, сохраняя целостность  
Аргументы  
text — входной текст для усечения  
model — модель, используемая для оценки длины токенов  
max_tokens — максимальное количество токенов  
Возвращает  
Усечённый текст, укладывающийся в лимит

---
def _generate_section(llm: Any, llm_cache: Any, title: str, context: str, language: str) -> str  
Генерирует содержимое секции документации на основе контекста  
Аргументы  
llm — экземпляр языковой модели  
llm_cache — кэш для результатов LLM  
title — заголовок секции  
context — контекстный текст (например, объединённые аннотации)  
language — язык генерации (например, "ru", "en")  
Возвращает  
Сгенерированный текст секции без заголовка

---
def _is_test_path(path: str) -> bool  
Проверяет, является ли путь тестовым (по имени файла или директории)  
Аргументы  
path — путь к файлу  
Возвращает  
True, если путь соответствует тестовому файлу

---
def _save_cache_snapshot() -> None  
Сохраняет текущее состояние кэша LLM на диск  
Исключения  
Может выбрасывать исключения при ошибках записи, не обрабатываются напрямую

---
def generate_docs(llm: Any, llm_cache: Any, file_map: Dict, docs_dir: Path, output_root: Path, language: str, input_budget: int, executor: Optional[Any] = None, force: bool = False, write_readme: bool = False, write_mkdocs: bool = False, local_site: bool = False, use_cache: bool = True) -> None  
Основная процедура генерации документации по проекту  
Аргументы  
llm — экземпляр языковой модели для генерации текстов  
llm_cache — кэш для хранения и повторного использования ответов LLM  
file_map — карта файлов проекта с их содержимым и метаданными  
docs_dir — директория вывода для сгенерированной документации  
output_root — корневая директория проекта  
language — язык документации (например, "ru" или "en")  
input_budget — лимит токенов для контекста LLM  
executor — пул потоков для асинхронной генерации секций (опционально)  
force — флаг перезаписи существующих файлов  
write_readme — флаг генерации README.md  
write_mkdocs — флаг сборки документации через MkDocs  
local_site — флаг локальной публикации сайта  
use_cache — флаг использования кэширования  
Возвращает  
None  
Исключения  
RuntimeError — если mkdocs не установлен при включённой опции write_mkdocs

---
def _collect_dependencies(file_map: Dict) -> List[str]  
Собирает список внешних зависимостей проекта на основе анализа импортов  
Аргументы  
file_map — карта файлов проекта с содержимым и метаданными  
Возвращает  
Список строк с названиями зависимостей

---
def _truncate_context(text: str, model: str, budget: int) -> str  
Обрезает контекст до указанного лимита токенов модели  
Аргументы  
text — входной текст  
model — название модели для оценки длины токенов  
budget — максимальное количество токенов  
Возвращает  
Обрезанный текст, укладывающийся в лимит

---
def _build_docs_index(output_root: Path, docs_dir: Path, docs_files: Dict[str, str], file_map: Dict[str, Dict], module_pages: Dict[str, str]) -> Dict[str, object]  
Формирует JSON-индекс документации для навигации и поиска  
Аргументы  
output_root — корневая директория вывода  
docs_dir — директория с документацией  
docs_files — словарь сгенерированных файлов  
file_map — карта исходных файлов  
module_pages — страницы модулей в формате путь → содержимое  
Возвращает  
Словарь с древовидной структурой документации

---
def write_docs_files(docs_dir: Path, docs_files: Dict[str, str]) -> None  
Записывает все сгенерированные файлы в файловую систему  
Аргументы  
docs_dir — директория назначения  
docs_files — словарь путей и содержимого файлов  
Возвращает  
None

---
def _generate_readme(llm: Any, llm_cache: Any, project_name: str, overview_context: str, language: str) -> str  
Генерирует содержимое README.md на основе общего контекста проекта  
Аргументы  
llm — экземпляр языковой модели  
llm_cache — кэш LLM  
project_name — имя проекта  
overview_context — обобщённый контекст проекта  
language — язык документации  
Возвращает  
Текст README.md

---
def build_mkdocs_yaml(site_name: str, sections: Dict[str, str], configs: List[str], has_modules: bool, module_nav_paths: List[str], local_site: bool) -> str  
Генерирует содержимое файла mkdocs.yml для сборки сайта документации  
Аргументы  
site_name — имя сайта документации  
sections — заголовки секций  
configs — список написанных конфигурационных файлов  
has_modules — флаг наличия модулей  
module_nav_paths — пути навигации по модулям  
local_site — флаг локальной публикации  
Возвращает  
Строку в формате YAML

---
def format_changes_md(added: Dict, modified: Dict, deleted: Dict, regenerated_sections: List[str], summary: str) -> str  
Форматирует Markdown-представление изменений в проекте  
Аргументы  
added — словарь добавленных файлов  
modified — словарь изменённых файлов  
deleted — словарь удалённых файлов  
regenerated_sections — список перегенерированных секций  
summary — краткое резюме изменений от LLM  
Возвращает  
Строку в формате Markdown
