# ai_docs/tokenizer

Модуль предоставляет инструменты для подсчёта токенов и разбиения текста на части с учётом ограничений по количеству токенов, используя кодировку, соответствующую указанной модели OpenAI. Основная функциональность опирается на библиотеку `tiktoken`. В случае отсутствия модели в списке поддерживаемых, используется базовая кодировка `cl100k_base`.

Ключевые структуры данных
None — Модуль не определяет пользовательских типов или структур данных.

---
get_encoding(model: str)
Возвращает кодировку токенизатора для указанной модели, при отсутствии — резервную кодировку.
Аргументы
model — Название модели, для которой запрашивается кодировка (например, "gpt-4", "gpt-3.5-turbo").
Возвращает
Объект кодировки из библиотеки tiktoken.
Исключения
Нет — Обработка отсутствующей модели осуществляется через возврат резервной кодировки.

---
count_tokens(text: str, model: str) -> int
Подсчитывает количество токенов в тексте с использованием кодировки модели.
Аргументы
text — Входной текст для подсчёта токенов.
model — Название модели, определяющей кодировку.
Возвращает
Количество токенов в закодированном тексте.
Исключения
Нет — Исключения от tiktoken обрабатываются внутри функции get_encoding.

---
chunk_text(text: str, model: str, max_tokens: int) -> List[str]
Разбивает текст на фрагменты, каждый из которых содержит не более max_tokens токенов.
Аргументы
text — Исходный текст, который необходимо разбить.
model — Название модели, используемой для определения кодировки.
max_tokens — Максимальное количество токенов в одном фрагменте.
Возвращает
Список строк, каждый элемент — декодированный фрагмент текста заданного размера.
Исключения
Нет — Обработка ошибок осуществляется на уровне get_encoding.
