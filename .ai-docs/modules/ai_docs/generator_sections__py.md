# ai_docs/generator_sections

```markdown
Модуль отвечает за генерацию технической документации на основе анализа кодовой базы, изменений в файлах и контекста от LLM.  
Он строит иерархический контекст, разбивает его на управляемые фрагменты, генерирует разделы документации (включая архитектуру, обзор, тестирование) и формирует финальный README.  
Поддерживается многоязычность, кэширование запросов к LLM и принудительное обновление определённых разделов.

Ключевые структуры данных  
file_map — словарь с метаинформацией о файлах проекта, включая тип, домены, путь к сводке  
llm_cache — кэш ответов LLM для ускорения повторной генерации  
DOMAIN_TITLES — отображение внутренних доменов в читаемые заголовки разделов

---
async def generate_section(llm, llm_cache: Dict[str, str], title: str, context: str, language: str) -> str  
Генерирует один раздел документации в формате Markdown с помощью LLM.  
Аргументы  
llm — объект модели языковой модели с методом chat  
llm_cache — словарь для кэширования ответов LLM  
title — заголовок генерируемого раздела  
context — контекст, на основе которого генерируется содержимое  
language — язык вывода (например, "ru", "en")  
Возвращает  
Сгенерированный текст раздела в формате Markdown, с удалённым дублирующим заголовком  
Исключения  
Возможны исключения от llm.chat (сетевые ошибки, таймауты)

---
async def generate_readme(llm, llm_cache: Dict[str, str], project_name: str, overview_context: str, language: str) -> str  
Формирует краткий README.md с обзором, быстрым стартом, архитектурой и ссылками.  
Аргументы  
llm — объект модели языковой модели  
llm_cache — кэш ответов LLM  
project_name — название проекта  
overview_context — обобщённый контекст проекта  
language — язык документации  
Возвращает  
Текст README в формате Markdown  
Исключения  
Возможны исключения от llm.chat

---
def truncate_context(context: str, model: str, max_tokens: int) -> str  
Обрезает контекст до указанного лимита токенов, если он превышает лимит.  
Аргументы  
context — исходный текст  
model — название модели для подсчёта токенов  
max_tokens — максимальное количество токенов  
Возвращает  
Обрезанный текст (первый чанк, если требуется разбиение)

---
async def summarize_chunk(llm, llm_cache: Dict[str, str], chunk: str, language: str, focus: str = "") -> str  
Сжимает фрагмент текста до краткого конспекта с сохранением ключевой информации.  
Аргументы  
llm — модель для генерации  
llm_cache — кэш LLM  
chunk — текстовый фрагмент для сжатия  
language — язык вывода  
focus — дополнительный фокус (необязательно)  
Возвращает  
Сжатый конспект на указанном языке  
Исключения  
Возможны исключения от llm.chat

---
async def build_hierarchical_context(llm, llm_cache: Dict[str, str], texts: List[str], max_tokens: int, language: str, label: str, focus: str = "") -> str  
Рекурсивно объединяет и сжимает список текстов до умещения в лимит токенов.  
Аргументы  
llm — модель для сжатия  
llm_cache — кэш LLM  
texts — список текстовых фрагментов  
max_tokens — максимальное число токенов в результате  
language — язык обработки  
label — метка для логирования  
focus — тематический фокус (опционально)  
Возвращает  
Сжатый и объединённый контекст, умещающийся в лимит токенов  
Исключения  
Возможны исключения от llm.chat

---
async def build_sections(file_map: Dict[str, Dict], added: Dict[str, Dict], modified: Dict[str, Dict], deleted: Dict[str, Dict], docs_dir: Path, llm, llm_cache: Dict[str, str], language: str, threads: int, input_budget: int, force_sections: Optional[Set[str]] = None) -> Tuple[Dict[str, str], Dict[str, str], Dict[str, str], List[str], List[str], Dict[str, str], List[str], str]  
Основная функция построения всех разделов документации на основе изменений и контекста.  
Аргументы  
file_map — карта всех файлов проекта с метаданными  
added — добавленные файлы  
modified — изменённые файлы  
deleted — удалённые файлы  
docs_dir — путь к директории документации  
llm — модель для генерации текста  
llm_cache — кэш ответов LLM  
language — язык документации  
threads — количество параллельных потоков (не используется напрямую)  
input_budget — лимит токенов на вход  
force_sections — множество разделов, которые нужно перегенерировать принудительно  
Возвращает  
Кортеж из: контекстов доменов, сгенерированных разделов, контекстов модулей, путей тестов, команд тестов, зависимостей, имён изменённых доменов и обобщённого контекста проекта  
Исключения  
Возможны исключения от llm.chat и операций с файловой системой
```
