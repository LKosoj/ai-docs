# ai_docs/summary

Модуль предоставляет инструменты для генерации и сохранения документации по файлам исходного кода или конфигурациям с использованием LLM.  
Основная функция `summarize_file` разбивает содержимое файла на части, формирует промпты и генерирует краткое или подробное резюме.  
Результаты сохраняются в виде Markdown-файлов через функцию `write_summary` с безопасным именованием путей.  
Поддерживается кэширование ответов LLM для повышения производительности и избежания повторных запросов.

summarize_file(content: str, file_type: str, domains: List[str], llm_client, llm_cache: Dict[str, str], model: str, detailed: bool = False) -> str
Генерирует сводку содержимого файла с помощью LLM, с возможностью детализации и контекстной настройки промпта.
Аргументы
content — исходное содержимое файла для анализа
file_type — тип файла (например, "infra", "source" и т.п.), влияет на формирование промпта
domains — список доменов, к которым относится файл; используется для уточнения контекста в промпте
llm_client — клиент для взаимодействия с языковой моделью, должен поддерживать метод chat
llm_cache — словарь для кэширования ответов LLM, используется как хранилище ключ-значение
model — название модели LLM, используется для определения ограничений по токенам при разбиении текста
detailed — флаг, определяющий, использовать ли подробный промпт (Doxygen-стиль) или краткий
Возвращает
Строку с итоговой сводкой в формате Markdown

---
write_summary(summary_dir: Path, rel_path: str, summary: str) -> Path
Сохраняет сгенерированную сводку в файл Markdown в указанной директории с безопасным именем.
Аргументы
summary_dir — путь к директории, где будет сохранён файл сводки
rel_path — относительный путь к исходному файлу, используется для формирования имени выходного файла
summary — текст сводки, который будет записан в файл
Возвращает
Путь к созданному файлу с сохранённой сводкой
