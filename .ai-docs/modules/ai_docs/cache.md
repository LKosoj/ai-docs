# ai_docs/cache

```markdown
Класс `CacheManager` предназначен для управления кэшем файлов и промежуточных данных в приложении, включая индексацию файлов и кэширование ответов LLM. Он обеспечивает загрузку и сохранение данных в JSON-файлах, а также вычисление различий между текущим и предыдущим состояниями файловой системы. Каталог кэша инициализируется при создании экземпляра, а необходимые подкаталоги создаются автоматически.

CacheManager
Менеджер кэширования для хранения индекса файлов и кэша LLM.
Поля
cache_dir — корневая директория для хранения кэша
index_path — путь к файлу индекса (index.json)
llm_cache_path — путь к файлу кэша LLM (llm_cache.json)
Методы
__init__(cache_dir: Path) — инициализирует менеджер кэша и создает необходимые директории
load_index() -> Dict — загружает индекс файлов из JSON
save_index(data: Dict) -> None — сохраняет индекс файлов в JSON
load_llm_cache() -> Dict[str, str] — загружает кэш LLM из JSON
save_llm_cache(data: Dict[str, str]) -> None — сохраняет кэш LLM в JSON
diff_files(current_files: Dict[str, Dict]) -> Tuple[Dict, Dict, Dict, Dict] — вычисляет различия между текущими и предыдущими файлами

---
__init__(self, cache_dir: Path)
Инициализирует менеджер кэша и создает директорию кэша при необходимости.
Аргументы
cache_dir — путь к директории кэша

---
load_index(self) -> Dict
Загружает индекс файлов из файла index.json; возвращает пустую структуру, если файл не существует.
Возвращает
Словарь с данными индекса, содержащий ключи "files" и "sections"

---
save_index(self, data: Dict) -> None
Сохраняет переданный словарь в файл index.json в формате JSON с форматированием.
Аргументы
data — данные индекса для сохранения

---
load_llm_cache(self) -> Dict[str, str]
Загружает кэш LLM из файла llm_cache.json; возвращает пустой словарь, если файл не существует.
Возвращает
Словарь с кэшированными ответами LLM в формате {ключ: ответ}

---
save_llm_cache(self, data: Dict[str, str]) -> None
Сохраняет кэш LLM в файл llm_cache.json в формате JSON с форматированием.
Аргументы
data — словарь с кэшированными ответами LLM для сохранения

---
diff_files(self, current_files: Dict[str, Dict]) -> Tuple[Dict, Dict, Dict, Dict]
Сравнивает текущие метаданные файлов с сохранёнными в индексе и возвращает четыре группы: добавленные, изменённые, удалённые и неизменные файлы.
Аргументы
current_files — словарь с текущими метаданными файлов, ключ — путь, значение — метаданные (включая хеш)
Возвращает
Кортеж из четырёх словарей: (добавленные, изменённые, удалённые, неизменные) файлы
```
