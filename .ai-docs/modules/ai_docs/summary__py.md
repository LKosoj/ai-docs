# ai_docs/summary

Модуль предоставляет инструменты для генерации и обработки документации по исходным файлам с использованием LLM.  
Основная функциональность включает разбиение текста на части, формирование кратких описаний файлов и нормализацию результата в единый стиль Doxygen.  
Поддерживается кэширование ответов LLM и корректная запись результатов в файловую систему.

Ключевые структуры данных  
llm_cache — словарь для кэширования ответов LLM по ключу запроса  
domains — список доменов, связанных с инфраструктурным файлом

summarize_file(content: str, file_type: str, domains: List[str], llm_client, llm_cache: Dict[str, str], model: str, detailed: bool = False) -> str  
Формирует краткое или детализированное описание содержимого файла с помощью LLM  
Аргументы  
content — исходное содержимое файла для анализа  
file_type — тип файла (например, "infra", "source" и т.п.)  
domains — список доменов, к которым относится файл (актуально для инфраструктурных файлов)  
llm_client — клиент для взаимодействия с языковой моделью  
llm_cache — словарь для кэширования ответов LLM  
model — модель LLM, используемая для оценки длины токенов  
detailed — флаг, указывающий, требуется ли детальная документация в стиле Doxygen  
Возвращает  
Строка с кратким или структурированным описанием файла в формате Markdown  
Исключения  
Может выбрасывать исключения, связанные с сетевым взаимодействием через llm_client

---
write_summary(summary_dir: Path, rel_path: str, summary: str) -> Path  
Записывает сгенерированное резюме файла в указанный каталог в виде Markdown-файла  
Аргументы  
summary_dir — каталог для сохранения резюме  
rel_path — относительный путь к исходному файлу (используется для генерации имени выходного файла)  
summary — текст резюме для записи  
Возвращает  
Путь к созданному файлу с резюме  
Исключения  
Может выбрасывать исключения при ошибках доступа к файловой системе

---
_normalize_module_summary(summary: str, llm_client, llm_cache: Dict[str, str]) -> str  
Нормализует текст резюме модуля к строгому формату Doxygen, устраняя несоответствия стиля  
Аргументы  
summary — исходный текст резюме, возможно, с нарушениями формата  
llm_client — клиент для вызова языковой модели  
llm_cache — кэш для повторных запросов к LLM  
Возвращает  
Отформатированный текст, соответствующий Doxygen-стилю  
Исключения  
Может выбрасывать исключения при ошибках взаимодействия с LLM

---
_strip_fenced_markdown(text: str) -> str  
Удаляет ограничивающие маркеры кода (```) из строки, если они присутствуют  
Аргументы  
text — входной текст, возможно, обёрнутый в блок кода  
Возвращает  
Текст без маркеров начала и конца блока кода

---
_needs_doxygen_fix(text: str) -> bool  
Проверяет, содержит ли текст признаки несоответствия Doxygen-формату  
Аргументы  
text — текст резюме для проверки  
Возвращает  
True, если текст требует переформатирования, иначе False
