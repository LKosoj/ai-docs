# OpenAI configuration
OPENAI_API_KEY=your_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini
# Model context length (required)
OPENAI_CONTEXT_TOKENS=128000
OPENAI_MAX_TOKENS=12000
# Optional generation params
OPENAI_TEMPERATURE=0.2
# Optional: output tokens per response (set outside .env if you prefer)
# OPENAI_MAX_TOKENS=1200

# Optional: parallel LLM workers (CLI --threads overrides)
AI_DOCS_THREADS=5

# Optional: local MkDocs config (CLI --local-site overrides)
AI_DOCS_LOCAL_SITE=false
