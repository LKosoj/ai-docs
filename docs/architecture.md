# Архитектура

## Общая структура

`ai_docs` — модульная CLI-утилита для автоматической генерации технической документации. Архитектура построена по принципу разделения ответственности: каждый компонент отвечает за конкретный этап обработки — от сканирования исходников до финальной сборки сайта.

```
ai_docs/
├── cli/                  # Точка входа и обработка аргументов
├── scanner.py            # Сканирование файлов и фильтрация
├── cache.py              # Кэширование индексов и LLM-ответов
├── llm.py                # Взаимодействие с языковыми моделями
├── tokenizer.py          # Токенизация и чанкинг текста
├── utils.py              # Вспомогательные функции (хеши, пути, бинарные файлы)
├── classify.py           # Классификация типов файлов и доменов
├── generate_docs.py      # Генерация контента документации
├── mkdocs.py             # Формирование mkdocs.yml и структуры docs/
├── changes.py            # Формирование отчёта об изменениях
└── tests/                # Юнит-тесты для ключевых модулей
```

## Ключевые компоненты

### 1. `scanner.py` — Сбор и фильтрация файлов

- **Назначение**: рекурсивный обход файловой системы или клонирование Git-репозитория с фильтрацией по `.gitignore`, паттернам и размеру.
- **Вход**: `--source` (путь или URL), `--include`, `--exclude`, `--max-size`.
- **Выход**: `ScanResult` — список файлов с метаданными (путь, тип, домены).
- **Особенности**:
  - Использует `pathspec` для корректной обработки `.gitignore`.
  - Клонирует удалённые репозитории с `--depth 1`.
  - Исключает `node_modules`, `.venv`, `build`, `.ai_docs_cache` и другие типовые директории.
  - Определяет домены (Kubernetes, Terraform и др.) через `detect_domains`.

### 2. `cache.py` — Инкрементальная обработка

- **Назначение**: минимизация повторной обработки за счёт кэширования.
- **Файлы кэша**:
  - `.ai_docs_cache/index.json` — хеши файлов и статусы.
  - `.ai_docs_cache/llm_cache.json` — ответы LLM по хешу запроса.
- **Методы**:
  - `diff_files()` — определяет `added`, `modified`, `deleted`, `unchanged`.
  - `load_index()` / `save_index()` — сериализация индекса.
- **Поведение**: при запуске сравнивает текущее состояние с кэшем, пересчитывает только изменённые файлы.

### 3. `llm.py` — Взаимодействие с LLM

- **Класс**: `LLMClient` — унифицированный интерфейс к OpenAI-совместимым API.
- **Параметры**:
  - `OPENAI_API_KEY`, `OPENAI_BASE_URL`, `OPENAI_MODEL` — из `.env`.
  - `temperature=0.2`, `max_tokens=1200`, `context_limit=8192`.
- **Кэширование**: запросы хешируются по SHA-256 нормализованного JSON-тела.
- **Безопасность**: потокобезопасный доступ к кэшу через `threading.Lock`.

### 4. `tokenizer.py` — Управление контекстом

- **Зависимость**: `tiktoken` для точного подсчёта токенов.
- **Функции**:
  - `count_tokens(text, model)` — подсчёт токенов.
  - `chunk_text(text, model, max_tokens)` — разбиение на чанки с учётом лимита модели.
- **Использование**: при суммаризации больших файлов, чтобы не превысить лимит контекста.

### 5. `generate_docs.py` — Генерация контента

- **Основные функции**:
  - `summarize_file()` — генерация краткого описания файла через LLM.
  - `_generate_section()` — создание разделов: архитектура, запуск, зависимости.
  - `_generate_readme()` — формирование `README.md`.
- **Параллелизм**: обработка файлов в `ThreadPoolExecutor` (управляется `--threads`).
- **Локализация**: поддержка `ru`/`en` через `SECTION_TITLES`, `DOMAIN_TITLES`.

### 6. `mkdocs.py` — Сборка документации

- **Функции**:
  - `build_mkdocs_yaml()` — генерация `mkdocs.yml` с учётом активных разделов и доменов.
  - `write_docs_files()` — запись Markdown-файлов в `docs/`.
- **Особенности**:
  - При `--local-site` отключает `use_directory_urls` и `site_url` для корректной работы локально.
  - Автоматически включает `changes.md` в навигацию.

### 7. `classify.py` — Классификация файлов

- **Функции**:
  - `classify_type()` — определяет тип: `code`, `config`, `docs`, `infra`, `ci`.
  - `detect_domains()` — выявляет технологии: `kubernetes`, `terraform`, `docker` и др.
  - `is_infra()` — проверка, относится ли файл к инфраструктуре.
- **Использование**: влияет на приоритет обработки и включение в раздел "Конфиги".

## Поток выполнения

1. **Инициализация**:
   - Парсинг аргументов CLI.
   - Загрузка переменных окружения.
   - Создание `LLMClient`.

2. **Сканирование**:
   - `scan_source()` — обход или клонирование.
   - Фильтрация по `.gitignore`, размеру, паттернам.
   - Классификация типов и доменов.

3. **Кэширование**:
   - Загрузка `index.json`.
   - Сравнение с текущим состоянием (`diff_files`).
   - Определение файлов для пересчёта.

4. **Генерация**:
   - Суммаризация файлов через `summarize_file()` с кэшированием.
   - Генерация разделов документации.
   - Формирование `README.md`.

5. **Вывод**:
   - Запись `docs/` и `mkdocs.yml`.
   - Формирование `changes.md`.
   - Сборка сайта: `mkdocs build`.

6. **Очистка**:
   - Удаление временных директорий (для URL-источников).
   - Сохранение обновлённого кэша.

## Интеграция и расширяемость

- **CI/CD**: поддержка автоматической генерации при коммите.
- **Локальный запуск**: `--local-site` для предпросмотра без веб-сервера.
- **Расширение доменов**: добавление новых паттернов в `classify.py`.
- **Поддержка LLM**: любой OpenAI-совместимый API через `OPENAI_BASE_URL`.

Архитектура обеспечивает высокую производительность за счёт кэширования, отказоустойчивость и гибкость настройки под различные стеки и процессы.
